{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cf3dcdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    id                                                url  \\\n",
      "0  1655159652990976000  https://x.com/elonmusk/status/1655159652990976000   \n",
      "1  1657261624867299339  https://x.com/elonmusk/status/1657261624867299339   \n",
      "2  1623774484795920384  https://x.com/elonmusk/status/1623774484795920384   \n",
      "3  1656900119202254854  https://x.com/elonmusk/status/1656900119202254854   \n",
      "4  1616531874763116544  https://x.com/elonmusk/status/1616531874763116544   \n",
      "\n",
      "                                          twitterUrl  \\\n",
      "0  https://twitter.com/elonmusk/status/1655159652...   \n",
      "1  https://twitter.com/elonmusk/status/1657261624...   \n",
      "2  https://twitter.com/elonmusk/status/1623774484...   \n",
      "3  https://twitter.com/elonmusk/status/1656900119...   \n",
      "4  https://twitter.com/elonmusk/status/1616531874...   \n",
      "\n",
      "                                            fullText  retweetCount  \\\n",
      "0  RT @einarvollset: I read @paulg’s  “How to Mak...           NaN   \n",
      "1                            https://t.co/Zjn6r15lrR           NaN   \n",
      "2  RT @BillyM2k: dude bookmarks are an awesome tw...           NaN   \n",
      "3                         Event Horizon Balance Beam           NaN   \n",
      "4  RT @BillyM2k: @elonmusk oh that’s actually pre...           NaN   \n",
      "\n",
      "   replyCount  likeCount  quoteCount  viewCount                  createdAt  \\\n",
      "0         NaN        NaN         NaN        NaN  2023-05-07 10:36:27+00:00   \n",
      "1         NaN        NaN         NaN        NaN  2023-05-13 05:48:56+00:00   \n",
      "2         NaN        NaN         NaN        NaN  2023-02-09 20:03:00+00:00   \n",
      "3         NaN        NaN         NaN        NaN  2023-05-12 05:52:26+00:00   \n",
      "4         NaN        NaN         NaN        NaN  2023-01-20 20:23:27+00:00   \n",
      "\n",
      "   ...  inReplyToUserId inReplyToUsername  isPinned  isRetweet  isQuote  \\\n",
      "0  ...              NaN               NaN       NaN        NaN      NaN   \n",
      "1  ...              NaN               NaN       NaN        NaN      NaN   \n",
      "2  ...              NaN               NaN       NaN        NaN      NaN   \n",
      "3  ...              NaN               NaN       NaN        NaN      NaN   \n",
      "4  ...              NaN               NaN       NaN        NaN      NaN   \n",
      "\n",
      "  isConversationControlled possiblySensitive quoteId quote retweet  \n",
      "0                      NaN               NaN     NaN   NaN     NaN  \n",
      "1                      NaN               NaN     NaN   NaN     NaN  \n",
      "2                      NaN               NaN     NaN   NaN     NaN  \n",
      "3                      NaN               NaN     NaN   NaN     NaN  \n",
      "4                      NaN               NaN     NaN   NaN     NaN  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "         Date  Adj Close     Close      High       Low      Open     Volume\n",
      "0  2010-06-29   1.592667  1.592667  1.666667  1.169333  1.266667  281494500\n",
      "1  2010-06-30   1.588667  1.588667  2.028000  1.553333  1.719333  257806500\n",
      "2  2010-07-01   1.464000  1.464000  1.728000  1.351333  1.666667  123282000\n",
      "3  2010-07-02   1.280000  1.280000  1.540000  1.247333  1.533333   77097000\n",
      "4  2010-07-06   1.074000  1.074000  1.333333  1.055333  1.333333  103003500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cw/6fvc9pxs3358jj5gxt73_bth0000gn/T/ipykernel_55958/792248898.py:6: DtypeWarning: Columns (11,16,17,18,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  tweets_df = pd.read_csv(\"../data/raw/elonmusk_raw.csv\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "\n",
    "# Load raw data\n",
    "tweets_df = pd.read_csv(\"../data/raw/elonmusk_raw.csv\")\n",
    "stock_df = pd.read_csv(\"../data/raw/teslastock_raw.csv\")\n",
    "\n",
    "print(tweets_df.head())\n",
    "print(stock_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd4edb39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 20733 / 55099 NaN values\n",
      "Samples in dataset: 34366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cw/6fvc9pxs3358jj5gxt73_bth0000gn/T/ipykernel_55958/993094292.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  inputs[\"Date\"] = pd.to_datetime(inputs[\"createdAt\"]).dt.date\n",
      "/var/folders/cw/6fvc9pxs3358jj5gxt73_bth0000gn/T/ipykernel_55958/993094292.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  labels[\"Date\"] = pd.to_datetime(labels[\"Date\"]).dt.date\n"
     ]
    }
   ],
   "source": [
    "# Drop unnecessary columns\n",
    "inputs = tweets_df[[\"createdAt\", \"fullText\"]]\n",
    "labels = stock_df[[\"Date\", \"Open\", \"Close\"]]\n",
    "\n",
    "# Merge datasets on date\n",
    "inputs[\"Date\"] = pd.to_datetime(inputs[\"createdAt\"]).dt.date\n",
    "labels[\"Date\"] = pd.to_datetime(labels[\"Date\"]).dt.date\n",
    "data = pd.merge(inputs, labels, on=\"Date\", how=\"left\")\n",
    "\n",
    "# create daily change column to be used as continuous label\n",
    "data[\"day_change\"] = data[\"Close\"] - data[\"Open\"]\n",
    "\n",
    "# Basic preprocessing - check and remove for NaN values\n",
    "print(f'Dropping {data[\"day_change\"].isna().sum()} / {len(data)} NaN values')\n",
    "data = data.dropna(subset=[\"day_change\"])\n",
    "\n",
    "print(\"Samples in dataset:\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a43133d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 24056, Val size: 5155, Test size: 5155\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split it into train, val and test sets\n",
    "X, y = data[[\"fullText\"]], data[\"day_change\"]\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, shuffle=True)\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.50, shuffle=True\n",
    ")\n",
    "\n",
    "print(f\"Train size: {len(X_train)}, Val size: {len(X_val)}, Test size: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1520f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24056, 24203)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's vectorize the text data - use bag of words for simplicity and baseline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "bow_vectorizer = CountVectorizer()\n",
    "X_train_bow = bow_vectorizer.fit_transform(X_train[\"fullText\"])\n",
    "X_val_bow = bow_vectorizer.transform(X_val[\"fullText\"])\n",
    "\n",
    "X_train_bow.shape  # second dimension gives the vocab size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dea568cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R2: 0.7195640785765807, Train MSE: 13.317850195816819\n",
      "Validation R2: -18.12687994289484, Validation MSE: 888.6973676683656\n"
     ]
    }
   ],
   "source": [
    "# Lets finally fit a linear regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "def fit_linear_model(model, X_train, y_train, X_val, y_val):\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Get metrics\n",
    "    R2_train = model.score(X_train, y_train)\n",
    "    MSE_train = mean_squared_error(y_train, model.predict(X_train))\n",
    "\n",
    "    R2_val = model.score(X_val, y_val)\n",
    "    MSE_val = mean_squared_error(y_val, model.predict(X_val))\n",
    "\n",
    "    print(f\"Train R2: {R2_train}, Train MSE: {MSE_train}\")\n",
    "    print(f\"Validation R2: {R2_val}, Validation MSE: {MSE_val}\")\n",
    "\n",
    "\n",
    "fit_linear_model(LinearRegression(), X_train_bow, y_train, X_val_bow, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e496bfb7",
   "metadata": {},
   "source": [
    "We can see that the simple Bag-of-words vectorization + linear regression overfits badly (low train error, high validation error). However, we have established a baseline.\n",
    "\n",
    "To make our baseline slightly better, we can try to reduce our model's complexity by using some regularization: Ridge and Lasso Regression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87ec4a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Ridge Regression ===\n",
      "Train R2: 0.5465154048775713, Train MSE: 21.53589979948549\n",
      "Validation R2: -0.2468215870331516, Validation MSE: 57.93140677709266\n",
      "=== Lasso Regression ===\n",
      "Train R2: 0.0, Train MSE: 47.48981559929589\n",
      "Validation R2: -0.0007537706181983683, Validation MSE: 46.49829163396627\n"
     ]
    }
   ],
   "source": [
    "# Fit regularized linear models - Ridge and Lasso\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "\n",
    "# default hyperparameters used\n",
    "print(\"=== Ridge Regression ===\")\n",
    "fit_linear_model(Ridge(alpha=1.0), X_train_bow, y_train, X_val_bow, y_val)\n",
    "\n",
    "print(\"=== Lasso Regression ===\")\n",
    "fit_linear_model(Lasso(alpha=1.0), X_train_bow, y_train, X_val_bow, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7067a9",
   "metadata": {},
   "source": [
    "Regularization seems to have improved our baseline's performance significantly compared to vanilla OLS, but still nowhere near where where we'd like to be. Using Lasso (which is implicitly a form of feature selection as well, since certain parameters will simply go to 0 during training), we've managed to get an R^2 of approximately 0, which is approximately what we would expect if simply using the mean of the training dataset. It's simply better to predict the mean at the moment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6781da",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
