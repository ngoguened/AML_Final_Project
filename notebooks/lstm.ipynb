{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a970004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    \"\"\"\n",
    "    A simple LSTM model for sequence data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, input_size, hidden_size, num_layers, output_size, dropout_rate=0.5\n",
    "    ):\n",
    "        \"\"\"\n",
    "        :param input_size: The number of expected features in the input (e.g., word embedding dimension).\n",
    "        :param hidden_size: The number of features in the hidden state h.\n",
    "        :param num_layers: The number of recurrent layers.\n",
    "        :param output_size: The number of output features (e.g., number of classes).\n",
    "        \"\"\"\n",
    "        super(LSTMModel, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # 1. The core LSTM layer\n",
    "        # batch_first=True makes input/output tensors shaped as (batch_size, seq_len, features)\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size, hidden_size, num_layers, batch_first=True, dropout=dropout_rate\n",
    "        )\n",
    "\n",
    "        # 2. Fully connected layer for output\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        # 3. Optional: Activation function for the final output (e.g., for classification)\n",
    "        # self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, seq_len, input_size)\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # Initialize hidden and cell states\n",
    "        # The states must be initialized for the current batch and moved to the same device as the input.\n",
    "        # h0 shape: (num_layers, batch_size, hidden_size)\n",
    "        # c0 shape: (num_layers, batch_size, hidden_size)\n",
    "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(x.device)\n",
    "\n",
    "        # LSTM forward pass\n",
    "        # output shape: (batch_size, seq_len, hidden_size)\n",
    "        # hn shape: (num_layers, batch_size, hidden_size)\n",
    "        # cn shape: (num_layers, batch_size, hidden_size)\n",
    "        output, (hn, cn) = self.lstm(x, (h0, c0))\n",
    "\n",
    "        # We typically use the output from the last time step for prediction.\n",
    "        # This is contained in the hidden state (hn) for the last layer (hn[-1]).\n",
    "        # The output tensor also contains all time steps, so we can use output[:, -1, :]\n",
    "\n",
    "        # Option A: Use the hidden state of the last layer at the last time step\n",
    "        # out = self.fc(hn[-1])\n",
    "\n",
    "        # Option B: Use the output of the last time step (simpler)\n",
    "        # output[:, -1, :] selects the last time step's output for all sequences in the batch\n",
    "        out = self.fc(output[:, -1, :])\n",
    "\n",
    "        # Apply final activation if needed\n",
    "        # out = self.activation(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e91bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input shape: torch.Size([32, 20, 100])\n",
      "Output shape: torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration ---\n",
    "INPUT_DIM = 100  # e.g., embedding dimension\n",
    "HIDDEN_DIM = 128\n",
    "NUM_LAYERS = 2\n",
    "OUTPUT_DIM = 1  # e.g., binary classification (1) or a regression value (1)\n",
    "SEQUENCE_LEN = 20  # The number of time steps (words, minutes, etc.)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# --- Model Instantiation ---\n",
    "model = LSTMModel(\n",
    "    input_size=INPUT_DIM,\n",
    "    hidden_size=HIDDEN_DIM,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    output_size=OUTPUT_DIM,\n",
    ")\n",
    "\n",
    "# --- Dummy Data Creation ---\n",
    "# Simulate a batch of data: 32 sequences, each with 20 time steps, where each step has 100 features.\n",
    "dummy_input = torch.randn(BATCH_SIZE, SEQUENCE_LEN, INPUT_DIM)\n",
    "\n",
    "# --- Forward Pass ---\n",
    "predictions = model(dummy_input)\n",
    "\n",
    "# --- Check Shapes ---\n",
    "print(f\"\\nInput shape: {dummy_input.shape}\")\n",
    "print(f\"Output shape: {predictions.shape}\")\n",
    "# Expected output shape: (32, 1) -> 32 predictions, 1 output feature each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118b052d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_price_by_min = pd.read_csv(\"../data/raw/TSLA_5_year_by_min.csv\")\n",
    "stock_price_by_min_2018_2020 = pd.read_csv(\"../data/raw/TSLA_2018_to_2020.csv\")\n",
    "tweets = pd.read_csv(\"../data/raw/elonmusk_raw.csv\")\n",
    "\n",
    "stock_price_by_min = pd.concat(\n",
    "    [stock_price_by_min, stock_price_by_min_2018_2020]\n",
    ").drop_duplicates()\n",
    "\n",
    "\n",
    "NUM_MINUTES_AHEAD = 5\n",
    "\n",
    "tweet_wanted_attributes = [\"createdAt\", \"isRetweet\", \"isReply\", \"isQuote\", \"fullText\"]\n",
    "stock_wanted_attributes = [\"ts_event\", \"open\", \"close\"]\n",
    "\n",
    "# filtering for only original tweets\n",
    "X = tweets[tweet_wanted_attributes]\n",
    "X = X[(X[\"isRetweet\"] == False) & (X[\"isReply\"] == False) & (X[\"isQuote\"] == False)]\n",
    "print(f\"Number of original tweets: {len(X)} / {len(tweets)}\")\n",
    "\n",
    "# converting createdAt to datetime\n",
    "X[\"createdAt\"] = pd.to_datetime(X[\"createdAt\"])\n",
    "\n",
    "# featurizing day of week and hour of day using sin and cos transformations\n",
    "X[\"day_sin\"] = X[\"createdAt\"].dt.dayofweek.apply(lambda x: np.sin(2 * np.pi * x / 7))\n",
    "X[\"day_cos\"] = X[\"createdAt\"].dt.dayofweek.apply(lambda x: np.cos(2 * np.pi * x / 7))\n",
    "X[\"hour_sin\"] = X[\"createdAt\"].dt.hour.apply(lambda x: np.sin(2 * np.pi * x / 24))\n",
    "X[\"hour_cos\"] = X[\"createdAt\"].dt.hour.apply(lambda x: np.cos(2 * np.pi * x / 24))\n",
    "\n",
    "# lets now get the stock prices NUM_MINUTES_AHEAD after each tweet\n",
    "stock_price_by_min[\"ts_event\"] = pd.to_datetime(stock_price_by_min[\"ts_event\"])\n",
    "y = stock_price_by_min[stock_wanted_attributes]\n",
    "\n",
    "# create window start and end times to join on\n",
    "X[\"window_start_time\"] = X[\"createdAt\"].dt.ceil(\"min\")\n",
    "X[\"window_end_time\"] = X[\"window_start_time\"] + pd.Timedelta(minutes=NUM_MINUTES_AHEAD)\n",
    "\n",
    "X = X.sort_values(\"createdAt\").reset_index(drop=True)\n",
    "y = y.sort_values(\"ts_event\").reset_index(drop=True)\n",
    "\n",
    "# filter X to only have tweets that have stock price data after them\n",
    "X = X[y[\"ts_event\"].min() <= X[\"window_start_time\"]]\n",
    "# filter to weekdays and market hours (data is in UTC)\n",
    "# this range is a little wider to account for Daylight Savings Time changes\n",
    "X = X[\n",
    "    (X[\"createdAt\"].dt.dayofweek < 5)\n",
    "    & (X[\"createdAt\"].dt.hour >= 13)\n",
    "    & (X[\"createdAt\"].dt.hour < 21)\n",
    "]\n",
    "\n",
    "# join to get stock prices at the start of the window\n",
    "data = pd.merge_asof(\n",
    "    X, y, left_on=\"window_start_time\", right_on=\"ts_event\", direction=\"forward\"\n",
    ")\n",
    "# join to get stock prices at the end of the window\n",
    "data = pd.merge_asof(\n",
    "    data,\n",
    "    y,\n",
    "    left_on=\"window_end_time\",\n",
    "    right_on=\"ts_event\",\n",
    "    direction=\"forward\",\n",
    "    suffixes=(\"_start\", \"_end\"),\n",
    ")\n",
    "\n",
    "# 1. Use the sorted y for the rolling average calculation.\n",
    "y_for_merge = y.set_index(\"ts_event\").copy()\n",
    "\n",
    "# 2. Calculate the rolling average of the PREVIOUS 5 minutes.\n",
    "# If this is still constant, the issue is in the 'y' DataFrame itself.\n",
    "y_for_merge[\"avg_last_5_prices\"] = (\n",
    "    y_for_merge[\"close\"].rolling(window=\"5min\", closed=\"left\", min_periods=1).mean()\n",
    ")\n",
    "# 3. Merge this new feature back into 'data'.\n",
    "data = pd.merge_asof(\n",
    "    data,\n",
    "    y_for_merge[\"avg_last_5_prices\"].reset_index(),\n",
    "    left_on=\"window_start_time\",\n",
    "    right_on=\"ts_event\",\n",
    "    direction=\"backward\",\n",
    ")\n",
    "\n",
    "data[\"avg_last_5_prices\"] = (\n",
    "    10000 * (data[\"avg_last_5_prices\"] - data[\"open_start\"]) / data[\"open_start\"]\n",
    ")\n",
    "\n",
    "# calculate the % change and convert to basis points (0.01%) so we dont have to deal\n",
    "# with small decimals\n",
    "data[\"bps_change\"] = (\n",
    "    10000 * (data[\"close_end\"] - data[\"open_start\"]) / data[\"open_start\"]\n",
    ")\n",
    "\n",
    "# 4. Drop the extra ts_event column created by the merge_asof\n",
    "data = data.drop(columns=[\"ts_event\"])\n",
    "\n",
    "# drop unnecessary columns\n",
    "data = data.drop(\n",
    "    columns=[\n",
    "        \"createdAt\",\n",
    "        \"isRetweet\",\n",
    "        \"isReply\",\n",
    "        \"isQuote\",\n",
    "        \"ts_event_start\",\n",
    "        \"ts_event_end\",\n",
    "        \"open_start\",\n",
    "        \"open_end\",\n",
    "        \"close_start\",\n",
    "        \"close_end\",\n",
    "        \"window_start_time\",\n",
    "        \"window_end_time\",\n",
    "    ]\n",
    ")\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split it into train, val and test sets\n",
    "X, y = data[data.columns[:-1]], data[\"bps_change\"]\n",
    "\n",
    "# temporal split - no shuffling. 70-15-15 split\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, shuffle=False)\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.50, shuffle=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
